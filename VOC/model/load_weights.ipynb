{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = 80\n",
    "anchor_num = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_layers(cfg, in_channels, batch_norm=True):\n",
    "    layers = []\n",
    "    in_channels = in_channels\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [torch.nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d_layer = torch.nn.Conv2d(in_channels=in_channels, out_channels=v[0],\n",
    "                                           kernel_size=v[1], stride=v[2], padding=v[3], bias=False)\n",
    "            acvt_layer = torch.nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
    "            if batch_norm:\n",
    "                bn_layer = torch.nn.BatchNorm2d(num_features=v[0])\n",
    "                layers += [conv2d_layer, bn_layer, acvt_layer]\n",
    "            else:\n",
    "                layers += [conv2d_layer, acvt_layer]\n",
    "            in_channels = v[0]\n",
    "\n",
    "    return torch.nn.Sequential(*layers)\n",
    "\n",
    "def init_model_variables(model):\n",
    "    print(\"Initialize model's weights ...\")\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, torch.nn.Conv2d):\n",
    "            torch.nn.init.kaiming_normal_(tensor=m.weight, mode='fan_out')\n",
    "            if m.bias is not None:\n",
    "                torch.nn.init.constant_(tensor=m.bias, val=0.0)\n",
    "        elif isinstance(m, torch.nn.BatchNorm2d):\n",
    "            torch.nn.init.constant_(tensor=m.weight, val=1.0)\n",
    "            torch.nn.init.constant_(tensor=m.bias, val=0.0)\n",
    "        elif isinstance(m, torch.nn.Linear):\n",
    "            torch.nn.init.normal_(tensor=m.weight, mean=0.0, std=0.01)\n",
    "            torch.nn.init.constant_(tensor=m.bias, val=0.0)\n",
    "            \n",
    "\n",
    "class DarkNet19(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DarkNet19, self).__init__()\n",
    "        # [32, 3, 1, 1] represent the parameters in torch.nn.Conv2d:\n",
    "        # out_channels = 32\n",
    "        # kernel_size = 3\n",
    "        # stride = 1\n",
    "        # padding = 1\n",
    "        cfg = [[32, 3, 1, 1], 'M',\n",
    "               [64, 3, 1, 1], 'M',\n",
    "               [128, 3, 1, 1], [64, 1, 1, 0], [128, 3, 1, 1], 'M',\n",
    "               [256, 3, 1, 1], [128, 1, 1, 0], [256, 3, 1, 1], 'M',\n",
    "               [512, 3, 1, 1], [256, 1, 1, 0], [512, 3, 1, 1], [256, 1, 1, 0],\n",
    "               [512, 3, 1, 1],\n",
    "               'M', [1024, 3, 1, 1], [512, 1, 1, 0], [1024, 3, 1, 1], [512, 1, 1, 0], [1024, 3, 1, 1]]\n",
    "\n",
    "        self.front_layer = make_layers(cfg[:16], in_channels=3)\n",
    "        self.route_layer = make_layers(cfg[16:17], in_channels=256)\n",
    "        self.rear_layer = make_layers(cfg[17:], in_channels=512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature = self.front_layer(x)\n",
    "        route = self.route_layer(feature)\n",
    "        feature = self.rear_layer(route)\n",
    "\n",
    "        return route, feature\n",
    "\n",
    "\n",
    "class Backbone(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Backbone, self).__init__()\n",
    "        self.darknet19 = DarkNet19()\n",
    "\n",
    "        total_bbox_num = (5 + class_num) * anchor_num\n",
    "        yolov2_cfg = [[64, 1, 1, 0], [256, 3, 2, 1], [1024, 3, 1, 1], [total_bbox_num, 1, 1, 0]]\n",
    "        # passthrough layer\n",
    "        self.pth_layer = make_layers(yolov2_cfg[:2], in_channels=512)\n",
    "        # predict layer\n",
    "        self.yolo_layer = make_layers(yolov2_cfg[2:], in_channels=1280)\n",
    "        init_model_variables(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        route, feature = self.darknet19(x)\n",
    "        route = self.pth_layer(route)\n",
    "        feature = torch.cat([route, feature], dim=1)\n",
    "        output = self.yolo_layer(feature)\n",
    "        output = output.permute(0, 2, 3, 1)\n",
    "        return output  # 13, 13, 125\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = '/home/dk/jyl/Yolo/V2/ckpt/only_params_trained_yolo_coco'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage1_conv1.0.weight -->  torch.Size([32, 3, 3, 3])\n",
      "stage1_conv1.1.weight -->  torch.Size([32])\n",
      "stage1_conv1.1.bias -->  torch.Size([32])\n",
      "stage1_conv1.1.running_mean -->  torch.Size([32])\n",
      "stage1_conv1.1.running_var -->  torch.Size([32])\n",
      "stage1_conv2.0.weight -->  torch.Size([64, 32, 3, 3])\n",
      "stage1_conv2.1.weight -->  torch.Size([64])\n",
      "stage1_conv2.1.bias -->  torch.Size([64])\n",
      "stage1_conv2.1.running_mean -->  torch.Size([64])\n",
      "stage1_conv2.1.running_var -->  torch.Size([64])\n",
      "stage1_conv3.0.weight -->  torch.Size([128, 64, 3, 3])\n",
      "stage1_conv3.1.weight -->  torch.Size([128])\n",
      "stage1_conv3.1.bias -->  torch.Size([128])\n",
      "stage1_conv3.1.running_mean -->  torch.Size([128])\n",
      "stage1_conv3.1.running_var -->  torch.Size([128])\n",
      "stage1_conv4.0.weight -->  torch.Size([64, 128, 1, 1])\n",
      "stage1_conv4.1.weight -->  torch.Size([64])\n",
      "stage1_conv4.1.bias -->  torch.Size([64])\n",
      "stage1_conv4.1.running_mean -->  torch.Size([64])\n",
      "stage1_conv4.1.running_var -->  torch.Size([64])\n",
      "stage1_conv5.0.weight -->  torch.Size([128, 64, 3, 3])\n",
      "stage1_conv5.1.weight -->  torch.Size([128])\n",
      "stage1_conv5.1.bias -->  torch.Size([128])\n",
      "stage1_conv5.1.running_mean -->  torch.Size([128])\n",
      "stage1_conv5.1.running_var -->  torch.Size([128])\n",
      "stage1_conv6.0.weight -->  torch.Size([256, 128, 3, 3])\n",
      "stage1_conv6.1.weight -->  torch.Size([256])\n",
      "stage1_conv6.1.bias -->  torch.Size([256])\n",
      "stage1_conv6.1.running_mean -->  torch.Size([256])\n",
      "stage1_conv6.1.running_var -->  torch.Size([256])\n",
      "stage1_conv7.0.weight -->  torch.Size([128, 256, 1, 1])\n",
      "stage1_conv7.1.weight -->  torch.Size([128])\n",
      "stage1_conv7.1.bias -->  torch.Size([128])\n",
      "stage1_conv7.1.running_mean -->  torch.Size([128])\n",
      "stage1_conv7.1.running_var -->  torch.Size([128])\n",
      "stage1_conv8.0.weight -->  torch.Size([256, 128, 3, 3])\n",
      "stage1_conv8.1.weight -->  torch.Size([256])\n",
      "stage1_conv8.1.bias -->  torch.Size([256])\n",
      "stage1_conv8.1.running_mean -->  torch.Size([256])\n",
      "stage1_conv8.1.running_var -->  torch.Size([256])\n",
      "stage1_conv9.0.weight -->  torch.Size([512, 256, 3, 3])\n",
      "stage1_conv9.1.weight -->  torch.Size([512])\n",
      "stage1_conv9.1.bias -->  torch.Size([512])\n",
      "stage1_conv9.1.running_mean -->  torch.Size([512])\n",
      "stage1_conv9.1.running_var -->  torch.Size([512])\n",
      "stage1_conv10.0.weight -->  torch.Size([256, 512, 1, 1])\n",
      "stage1_conv10.1.weight -->  torch.Size([256])\n",
      "stage1_conv10.1.bias -->  torch.Size([256])\n",
      "stage1_conv10.1.running_mean -->  torch.Size([256])\n",
      "stage1_conv10.1.running_var -->  torch.Size([256])\n",
      "stage1_conv11.0.weight -->  torch.Size([512, 256, 3, 3])\n",
      "stage1_conv11.1.weight -->  torch.Size([512])\n",
      "stage1_conv11.1.bias -->  torch.Size([512])\n",
      "stage1_conv11.1.running_mean -->  torch.Size([512])\n",
      "stage1_conv11.1.running_var -->  torch.Size([512])\n",
      "stage1_conv12.0.weight -->  torch.Size([256, 512, 1, 1])\n",
      "stage1_conv12.1.weight -->  torch.Size([256])\n",
      "stage1_conv12.1.bias -->  torch.Size([256])\n",
      "stage1_conv12.1.running_mean -->  torch.Size([256])\n",
      "stage1_conv12.1.running_var -->  torch.Size([256])\n",
      "stage1_conv13.0.weight -->  torch.Size([512, 256, 3, 3])\n",
      "stage1_conv13.1.weight -->  torch.Size([512])\n",
      "stage1_conv13.1.bias -->  torch.Size([512])\n",
      "stage1_conv13.1.running_mean -->  torch.Size([512])\n",
      "stage1_conv13.1.running_var -->  torch.Size([512])\n",
      "stage2_a_conv1.0.weight -->  torch.Size([1024, 512, 3, 3])\n",
      "stage2_a_conv1.1.weight -->  torch.Size([1024])\n",
      "stage2_a_conv1.1.bias -->  torch.Size([1024])\n",
      "stage2_a_conv1.1.running_mean -->  torch.Size([1024])\n",
      "stage2_a_conv1.1.running_var -->  torch.Size([1024])\n",
      "stage2_a_conv2.0.weight -->  torch.Size([512, 1024, 1, 1])\n",
      "stage2_a_conv2.1.weight -->  torch.Size([512])\n",
      "stage2_a_conv2.1.bias -->  torch.Size([512])\n",
      "stage2_a_conv2.1.running_mean -->  torch.Size([512])\n",
      "stage2_a_conv2.1.running_var -->  torch.Size([512])\n",
      "stage2_a_conv3.0.weight -->  torch.Size([1024, 512, 3, 3])\n",
      "stage2_a_conv3.1.weight -->  torch.Size([1024])\n",
      "stage2_a_conv3.1.bias -->  torch.Size([1024])\n",
      "stage2_a_conv3.1.running_mean -->  torch.Size([1024])\n",
      "stage2_a_conv3.1.running_var -->  torch.Size([1024])\n",
      "stage2_a_conv4.0.weight -->  torch.Size([512, 1024, 1, 1])\n",
      "stage2_a_conv4.1.weight -->  torch.Size([512])\n",
      "stage2_a_conv4.1.bias -->  torch.Size([512])\n",
      "stage2_a_conv4.1.running_mean -->  torch.Size([512])\n",
      "stage2_a_conv4.1.running_var -->  torch.Size([512])\n",
      "stage2_a_conv5.0.weight -->  torch.Size([1024, 512, 3, 3])\n",
      "stage2_a_conv5.1.weight -->  torch.Size([1024])\n",
      "stage2_a_conv5.1.bias -->  torch.Size([1024])\n",
      "stage2_a_conv5.1.running_mean -->  torch.Size([1024])\n",
      "stage2_a_conv5.1.running_var -->  torch.Size([1024])\n",
      "stage2_a_conv6.0.weight -->  torch.Size([1024, 1024, 3, 3])\n",
      "stage2_a_conv6.1.weight -->  torch.Size([1024])\n",
      "stage2_a_conv6.1.bias -->  torch.Size([1024])\n",
      "stage2_a_conv6.1.running_mean -->  torch.Size([1024])\n",
      "stage2_a_conv6.1.running_var -->  torch.Size([1024])\n",
      "stage2_a_conv7.0.weight -->  torch.Size([1024, 1024, 3, 3])\n",
      "stage2_a_conv7.1.weight -->  torch.Size([1024])\n",
      "stage2_a_conv7.1.bias -->  torch.Size([1024])\n",
      "stage2_a_conv7.1.running_mean -->  torch.Size([1024])\n",
      "stage2_a_conv7.1.running_var -->  torch.Size([1024])\n",
      "stage2_b_conv.0.weight -->  torch.Size([64, 512, 1, 1])\n",
      "stage2_b_conv.1.weight -->  torch.Size([64])\n",
      "stage2_b_conv.1.bias -->  torch.Size([64])\n",
      "stage2_b_conv.1.running_mean -->  torch.Size([64])\n",
      "stage2_b_conv.1.running_var -->  torch.Size([64])\n",
      "stage3_conv1.0.weight -->  torch.Size([1024, 1280, 3, 3])\n",
      "stage3_conv1.1.weight -->  torch.Size([1024])\n",
      "stage3_conv1.1.bias -->  torch.Size([1024])\n",
      "stage3_conv1.1.running_mean -->  torch.Size([1024])\n",
      "stage3_conv1.1.running_var -->  torch.Size([1024])\n",
      "stage3_conv2.weight -->  torch.Size([425, 1024, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(ckpt_path)\n",
    "for k, v in ckpt.items():\n",
    "    print(k + ' --> ' , v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize model's weights ...\n"
     ]
    }
   ],
   "source": [
    "yolo = Backbone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 3, 3])\n",
      "torch.Size([32])\n",
      "BN Bias torch.Size([32])\n",
      "BN Weight torch.Size([32])\n",
      "BN running mean torch.Size([32])\n",
      "BN running var torch.Size([32])\n",
      "torch.Size([64, 32, 3, 3])\n",
      "torch.Size([64])\n",
      "BN Bias torch.Size([64])\n",
      "BN Weight torch.Size([64])\n",
      "BN running mean torch.Size([64])\n",
      "BN running var torch.Size([64])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([128])\n",
      "BN Bias torch.Size([128])\n",
      "BN Weight torch.Size([128])\n",
      "BN running mean torch.Size([128])\n",
      "BN running var torch.Size([128])\n",
      "torch.Size([64, 128, 1, 1])\n",
      "torch.Size([64])\n",
      "BN Bias torch.Size([64])\n",
      "BN Weight torch.Size([64])\n",
      "BN running mean torch.Size([64])\n",
      "BN running var torch.Size([64])\n",
      "torch.Size([128, 64, 3, 3])\n",
      "torch.Size([128])\n",
      "BN Bias torch.Size([128])\n",
      "BN Weight torch.Size([128])\n",
      "BN running mean torch.Size([128])\n",
      "BN running var torch.Size([128])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([256])\n",
      "BN Bias torch.Size([256])\n",
      "BN Weight torch.Size([256])\n",
      "BN running mean torch.Size([256])\n",
      "BN running var torch.Size([256])\n",
      "torch.Size([128, 256, 1, 1])\n",
      "torch.Size([128])\n",
      "BN Bias torch.Size([128])\n",
      "BN Weight torch.Size([128])\n",
      "BN running mean torch.Size([128])\n",
      "BN running var torch.Size([128])\n",
      "torch.Size([256, 128, 3, 3])\n",
      "torch.Size([256])\n",
      "BN Bias torch.Size([256])\n",
      "BN Weight torch.Size([256])\n",
      "BN running mean torch.Size([256])\n",
      "BN running var torch.Size([256])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([512])\n",
      "BN Bias torch.Size([512])\n",
      "BN Weight torch.Size([512])\n",
      "BN running mean torch.Size([512])\n",
      "BN running var torch.Size([512])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256])\n",
      "BN Bias torch.Size([256])\n",
      "BN Weight torch.Size([256])\n",
      "BN running mean torch.Size([256])\n",
      "BN running var torch.Size([256])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([512])\n",
      "BN Bias torch.Size([512])\n",
      "BN Weight torch.Size([512])\n",
      "BN running mean torch.Size([512])\n",
      "BN running var torch.Size([512])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256])\n",
      "BN Bias torch.Size([256])\n",
      "BN Weight torch.Size([256])\n",
      "BN running mean torch.Size([256])\n",
      "BN running var torch.Size([256])\n",
      "torch.Size([512, 256, 3, 3])\n",
      "torch.Size([512])\n",
      "BN Bias torch.Size([512])\n",
      "BN Weight torch.Size([512])\n",
      "BN running mean torch.Size([512])\n",
      "BN running var torch.Size([512])\n",
      "torch.Size([1024, 512, 3, 3])\n",
      "torch.Size([1024])\n",
      "BN Bias torch.Size([1024])\n",
      "BN Weight torch.Size([1024])\n",
      "BN running mean torch.Size([1024])\n",
      "BN running var torch.Size([1024])\n",
      "torch.Size([512, 1024, 1, 1])\n",
      "torch.Size([512])\n",
      "BN Bias torch.Size([512])\n",
      "BN Weight torch.Size([512])\n",
      "BN running mean torch.Size([512])\n",
      "BN running var torch.Size([512])\n",
      "torch.Size([1024, 512, 3, 3])\n",
      "torch.Size([1024])\n",
      "BN Bias torch.Size([1024])\n",
      "BN Weight torch.Size([1024])\n",
      "BN running mean torch.Size([1024])\n",
      "BN running var torch.Size([1024])\n",
      "torch.Size([512, 1024, 1, 1])\n",
      "torch.Size([512])\n",
      "BN Bias torch.Size([512])\n",
      "BN Weight torch.Size([512])\n",
      "BN running mean torch.Size([512])\n",
      "BN running var torch.Size([512])\n",
      "torch.Size([1024, 512, 3, 3])\n",
      "torch.Size([1024])\n",
      "BN Bias torch.Size([1024])\n",
      "BN Weight torch.Size([1024])\n",
      "BN running mean torch.Size([1024])\n",
      "BN running var torch.Size([1024])\n",
      "torch.Size([64, 512, 1, 1])\n",
      "torch.Size([64])\n",
      "BN Bias torch.Size([64])\n",
      "BN Weight torch.Size([64])\n",
      "BN running mean torch.Size([64])\n",
      "BN running var torch.Size([64])\n",
      "torch.Size([256, 64, 3, 3])\n",
      "torch.Size([256])\n",
      "BN Bias torch.Size([256])\n",
      "BN Weight torch.Size([256])\n",
      "BN running mean torch.Size([256])\n",
      "BN running var torch.Size([256])\n",
      "torch.Size([1024, 1280, 3, 3])\n",
      "torch.Size([1024])\n",
      "BN Bias torch.Size([1024])\n",
      "BN Weight torch.Size([1024])\n",
      "BN running mean torch.Size([1024])\n",
      "BN running var torch.Size([1024])\n",
      "torch.Size([425, 1024, 1, 1])\n",
      "torch.Size([425])\n",
      "BN Bias torch.Size([425])\n",
      "BN Weight torch.Size([425])\n",
      "BN running mean torch.Size([425])\n",
      "BN running var torch.Size([425])\n"
     ]
    }
   ],
   "source": [
    "for m in yolo.modules():\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        print(m.weight.shape)\n",
    "        print(m.bias.shape)\n",
    "#         print(m.)\n",
    "    if isinstance(m, torch.nn.BatchNorm2d):\n",
    "        print('BN Bias', m.bias.shape)\n",
    "        print('BN Weight', m.weight.shape)\n",
    "        print('BN running mean', m.running_mean.shape)\n",
    "        print('BN running var', m.running_var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
